# Публичный бейзлайн для задачи AIJ Multi-Agent AI
English [Readme](README_eng.md)
## Описание
Данный репозиторий содержит [реализацию](baseline_rus.ipynb) [VDN](https://arxiv.org/abs/1706.05296) - кооперативного 
мульти-агентного алгоритма обучения с подкреплением. VDN основан на предпосылке
о линейном разложении общей награды агентов, таким образом, общая награда
всех агентов представлена в виде суммы индивидуальных наград.
Несмотря на то, что данная предпосылка ограничивает класс обучаемых стратегий
только кооперативными вариантами, VDN все же является хорошим бейзлайном для 
многих задач мультиагентного обучения с подкреплением.

Данный бейзлайн позволяет получить целевую метрику (Mean Focal Score) около
42 при ее сабмите в тестовую систему (Случайная политика, для сравнения, 
получает ~4).

## Необходимые ресурсы
Обучение данного алгоритма занимает примерно 3 часа при наличии GPU и
требует ~15гб. оперативной памяти и ~1гб. памяти GPU. Чтобы уменьшить 
потребление оперативной памяти, можно сократить размер буфера данных в
конфиге обучения.

## Создание бейзлайн-решения

__Шаг 1:__ Установить зависимости при помощи команды ```pip install -r requirements.txt```.
Зависимости включают в себя [открытый репозиторий](https://github.com/AIRI-Institute/aij_multiagent_rl) 
с модулем `aij_multiagent_rl`, содержащим симулятор и базовый класс агентов для задачи.
В случае проблем с установкой, установите модуль из исходных файлов репозитория.

__Шаг 2:__ Поочередно выполнить параграфы [ноутбука](baseline_rus.ipynb).
Главным результатом работы ноутбука будет создание директории `submission_vdn`.

__Шаг 3:__ Запустить приложенные юнит-тесты для проверки работоспособности решения

1) Вставить путь до директории решения в [конфиг файл тестов](tests/test_config.yaml)
по ключу `submission_dir`. По умолчанию, значение этого поля `"submission_vdn"`, так
что вносить изменения не нужно. Тем не менее, вы можете заменить путь к решению
в будущем, если захотите проверить работоспособность ваших собственных сабмишенов.
2) Запустить юнит тесты при помощи команды  ```pytest tests``` в корне данного репозитория

__Шаг 4:__ Запаковать решение в .zip архив и отправить его в тестирующую систему.
**Важно:** файлы решения должны быть на верхнем уровне в запакованном архиве:

Правильно:
```
submission.zip
    ├── utils         # Директория с модулями, необходимыми для класса агента (опционально)
    ├── model.py      # Скрипт с реализацией класса агента(ов) и фабричного метода
    └── agents        # Директория с артефактами агентов (название фисировано) 
```
Не правильно:
```
submission.zip
    └── submission
        ├── utils         # Директория с модулями, необходимыми для класса агента (опционально)
        ├── model.py      # Скрипт с реализацией класса агента(ов) и фабричного метода
        └── agents        # Директория с артефактами агентов (название фисировано) 
```


## Юнит тесты
В данный репозиторий включены юнит тесты для проверки валидности решения. Сабмишен,
полученный в ходе выполнения приложенного ноутбука без изменений должен проходить 
процедуру тестирования (и оценки в тестовой системе) без ошибок. Процедура запуска тестов 
описана выше.

Стоит отметить, что в один из тестов включено тестирование скорости сэмплирования действий
агентами. Если конфигурация машины, на которой тесты запускаются, сильно отличается от 
конфигурации ресурсов контейнера в системе тестирования (см. раздел ограничения в [описании](https://dsworks.ru/champ/multiagent-ai)
задачи) возникающее предупреждение можно игнорировать, в противном случае, стоит обратить на
него внимание.

__Мы рекомендуем запускать тесты на своих решениях, прежде чем отправлять их в систему.__

## Docker
В репозиторий так же включены [файлы Docker](docker), при помощи которых можно
воспроизвести среду тестовой системы, в которой будет запущено ваше решение или
использовать их для локальной разработки.
